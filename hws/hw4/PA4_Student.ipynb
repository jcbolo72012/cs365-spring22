{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Gaussian MLE\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "I have $n=100$ pieces of indepdendent and identicially distrubuted (i.i.d) data related to some measurement that is drawn from a **normal distribution**.\n",
    "\n",
    "Your task is to write code that computes $\\mu_{MLE}$ and $\\sigma_{MLE}$, which represent the mean and standard deviation computed via MLE, respectively, of the underlying normal distribution for the dataset \"MLE_dataset.npy\"\n",
    "\n",
    "## Variable Definitions\n",
    "\n",
    "1. x = collection of data points ($x_1,x_2,...,x_n$). Loaded in as a numpy array of shape (100,)\n",
    "2. $\\mu$ = mean of the normal distribution\n",
    "3. $\\sigma$ = standard deviation of the normal distribution\n",
    "\n",
    "## Useful Numpy functions\n",
    "\n",
    "1. x.shape : returns a tuple that contains the dimension(s) of the numpy array variable name \"x\"\n",
    "\n",
    "## Starting information\n",
    "\n",
    "1. You are given \"MLE_dataset.npy\" which contains the aforementioned data in the form of a numpy array.\n",
    "\n",
    "2. You are also given a \"load\" function which, given the path to \"MLE_dataset.npy\", will load the values into a numpy array variable and return said variable.\n",
    "\n",
    "3. For a single piece of data, $x_i$, if the data is drawn from a normal distribution, the likelihood of that data given a normal distribution with parameterized by $\\mu$ and $\\sigma^2$ can be represented as:\n",
    "\n",
    "$$p(x_i | \\mu, \\sigma^2) = \\mathcal{N}(x_i; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} * \\text{exp} \\ [-\\frac{1}{2}(\\frac{x_i - \\mu}{\\sigma})^2]$$\n",
    "\n",
    "4. In our case, we aren't dealing with a single observation, but $n=100$ observations. Because our observations are **independent**, we can represent our likelihood function for all observations as the product of the individual observations:\n",
    "\n",
    "$$p(x | \\mu, \\sigma^2) = \\Pi_{i=1}^N \\mathcal{N}(x_i; \\mu, \\sigma^2) = (\\frac{1}{2\\pi\\sigma^2})^{n/2} * \\text{exp} \\ [-\\frac{1}{2}\\sum_{i=1}^N (\\frac{x_i - \\mu}{\\sigma})^2]$$\n",
    "\n",
    "## MLE estimates for $\\mu$ and $\\sigma^2$ \n",
    "\n",
    "$$\\mu_{MLE} = \\frac{1}{n} \\sum_{i=1}^n x_i$$\n",
    "\n",
    "$$ \\sigma^2_{MLE} = \\frac{1}{n} \\sum_{i=1}^n(x_i-\\mu_{MLE})^2$$\n",
    "\n",
    "\n",
    "## Task\n",
    "\n",
    "Using the starting information, your task is to:\n",
    "1. Write code that correctly finds $\\mu_{MLE}$ and $\\sigma_{MLE}$ for the data set \"MLE_dataset.npy\"\n",
    "\n",
    "## Restrictions:\n",
    "Failure to meet any of these conditions will result in point deductions\n",
    "\n",
    "1. I will only be looking at the code in the function \"MLE\" below. Please make sure any computations done are within the comment bounds of the function \"MLE\".\n",
    "2. Do not add any helper functions\n",
    "3. Do not change the input and output of \"load\" or \"MLE\" in the cell below\n",
    "4. If you are copying the code over to a .py file, the restrictions above still apply!! Please make sure to copy over the comment bounds as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.93099108790383\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load(path):\n",
    "    '''\n",
    "    loads \"MLE_dataset.npy\" given its path into variable 'dataset'. returns 'dataset'\n",
    "    '''\n",
    "    dataset = np.load(path)\n",
    "    return dataset\n",
    "    \n",
    "def MLE(dataset):\n",
    "    '''\n",
    "    Input:\n",
    "        dataset - numpy array of shape (100,) - containing the data drawn from unknown gaussian\n",
    "    \n",
    "    Output:\n",
    "        mu - float - MLE estimate of mu based on data\n",
    "        sigma - float - MLE estimate of sigma based on data\n",
    "    '''\n",
    "    mu = np.sum(dataset)/dataset.size\n",
    "    sigma = sum([(x - mu)**2 for x in dataset])/dataset.size\n",
    "    print(sigma)\n",
    "    \n",
    "    ''' YOUR CODE HERE '''\n",
    "\n",
    "    \n",
    "    ''' END YOUR CODE'''\n",
    "    \n",
    "    return mu, sigma\n",
    "\n",
    "'''YOUR TEST CODE BELOW HERE'''\n",
    "#load dataset. assumes data file is in same directory as code file\n",
    "dataset = load(\"./MLE_dataset.npy\")\n",
    "mu_sigma = MLE(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Gaussian EM\n",
    "\n",
    "## Problem statement\n",
    "\n",
    "Let us add a layer of difficulty to the problem of estimating the underlying distribution(s) of our data. Previously. we knew that all of our data came from a single underlying normal distribution.\n",
    "\n",
    "For this problem, I have gone out and collected a brand new data set consisting of $n=200$ data points. These data points are drawn from **one of two unknown gaussian distributions**.\n",
    "\n",
    "To keep the notation consistent, I will use the subscript ID $k = \\{0,1\\}$ to represent which gaussian a parameter/variable is referring to.\n",
    "\n",
    "For instance, $\\mu_k$ represents the mean of the gaussian with ID $k$. $\\mu_0$ represents the mean of the first gaussian, and $\\mu_1$ represents the mean of the second gaussian\n",
    "\n",
    "## Variable definitions\n",
    "\n",
    "1. $k$: id of the gaussian distributions. {0,1} \n",
    "2. $n$: number of data points. 200 in this case\n",
    "3. $\\mu_k$: the mean of normal distribution $k$\n",
    "4. $\\sigma_k$: the std of normal distribution $k$\n",
    "5. $\\pi_k$: the prior probability of normal distribution $k$\n",
    "7. $t$: current step number\n",
    "8. $z_i = k$: represents the idea that i-th data point was drawn from gaussian $k$\n",
    "9. $x_i$: i-th data point\n",
    "\n",
    "## Task Description:\n",
    "\n",
    "To make things clear, here is a list of things we do and don't know.\n",
    "\n",
    "**Do know:**\n",
    "1. Our data points, $X = x_1, x_2, ..., x_n$ for $n = 1$ to $n=200$\n",
    "2. $\\mu_0^{t=0}, \\sigma_0^{t=0}, \\pi_0^{t=0}$ which represent an initial guess for the  mean, std, and prior  of the first gaussian with ID $k=0$\n",
    "3. $\\mu_1^{t=0}, \\sigma_1^{t=0}, \\pi_1^{t=0}$ which represent an initial guess for the  mean, std, and prior  of the second gaussian with ID $k=1$\n",
    "4. $\\pi_0^{t=0}$ and $\\pi_1^{t=0}$ which represent an initial guess for the prior probabilities of gaussian 0 and gaussian 1, respectively\n",
    "5. The number of iterations your EM algorithm should run for. Do not worry about early stopping, just let it run the full number of iterations\n",
    "6. Let us define the variable $\\theta_k^t$ to be the set ($\\hat{\\mu_k^t}, \\hat{\\sigma_k^t}, \\hat{\\pi_k^t})$, which is our current estimate at time step t for the three unknown parameters of gaussian k. \n",
    "\n",
    "**Don't know:**\n",
    "1. The true means, $\\mu_0$ and $\\mu_1$ for both gaussian distributions\n",
    "2. The true standard deviations, $\\sigma_0$ and $\\sigma_1$ for both gaussian distributions \n",
    "3. Which gaussian distribution, $k=0$ or $k=1$, a point, $x_i$, came from.\n",
    "4. The true fraction of our points that came from gaussian $k=0$ and the true fraction of our points that came from gaussian $k=1$ (the prior probabilities)\n",
    "\n",
    "#### Note: The lecture example of EM had known priors and you were not asked to estimate the prior with EM. For this reason, the update rule for the priors, $\\pi_k$, has been supplied, and you will only need to implement it correctly to find the correct priors.\n",
    "\n",
    "Your end goal is to implement an algorithm that implements EM and returns the following:\n",
    "1. $\\hat{\\mu_0}, \\hat{\\sigma_0}, \\hat{\\pi_0}$ which represent the final EM estimate the mean, standard deviation (std), and prior of the first gaussian with ID $k=0$\n",
    "2. $\\hat{\\mu_0}, \\hat{\\sigma_0}, \\hat{\\pi_0}$ which represent the final EM estimate of the mean, standard deviation (std), and prior of the first gaussian with ID $k=1$\n",
    "\n",
    "\n",
    "### Useful functions\n",
    "\n",
    "1. array.shape - returns the shape as a tuple of a numpy array\n",
    "2. scipy.stats.norm(mean, std).pdf(value) - returns the value pdf(val) of a gaussian distribution paramaterized by (mean, std)\n",
    "\n",
    "### Restrictions\n",
    "\n",
    "Failure to meet any of these conditions will result in point deductions\n",
    "\n",
    "1. I will only be looking at the code in the function \"em\" below. Please make sure any computations you want to submit as your final answer are done within \"em\".\n",
    "2. Please make a clear separation between code that computes the E step and code that computes the M step. \n",
    "    - This is done by putting all E-step related code within the E-step comment bounds, and all M-step related code within the M-step comment bounds\n",
    "3. Do not change the values of any variables marked with the comment \"DO NOT CHANGE\"\n",
    "4. Your final answer must not use any libraries other than the ones already imported (numpy and scipy.stats)\n",
    "5. Your final answer must not use any functions in scipy.stats besides scipy.stats.norm(mean, std).pdf(value) which is defined above\n",
    "6. If you are copying the code over to a .py file, the restrictions still apply!! Please make sure to copy over the comment bounds as well\n",
    "7. do not change the input and output of \"load\" or \"em\" in the cell below\n",
    "8. Please do not have any calls to helper functions in your final answer\n",
    "\n",
    "### Task Order\n",
    "1. Determine the update rules for $\\mu_k^{t+1}$ and $\\sigma_k^{t+1}$ and write them in the cell below\n",
    "2. Code the E and M step\n",
    "3. Run and test your code on \"EM_dataset.py\"\n",
    "\n",
    "\n",
    "## E - Step\n",
    "$P(z_i = k | x_i, \\theta_k^t)$ reflects the responsibility the k-th gaussian has for the i-th data point\n",
    "$P(z_i = k | x_i, \\theta_k^t) = \\frac{P(x_i | z_i = k, \\theta_k^t)*\\pi_k^t}{P(x_i | \\theta_k^t)}$ \\\n",
    "$= \\frac{P(x_i | z_i = k, \\theta_k^t)*\\pi_k^t}{\\sum_{k=0}^{1}P(x_i | z_i = k, \\theta_k^t)*\\pi_k^t}$\n",
    "\n",
    "\n",
    "\n",
    "## M - Step\n",
    "\n",
    "\n",
    "$\\mu_k^{t+1} = \\ ??$\n",
    "\n",
    "$\\sigma_k^{t+1} = \\ ??$\n",
    "\n",
    "$\\pi_k^{t+1} = \\frac{\\sum_{i=1}^n P(z_i = k | x_i, \\theta_k^t)}{n}$\n",
    "\n",
    "\n",
    "**hint 1: You will need to use the result of your E-step, $P(z_i = k | x_i, \\theta_k^t)$, in your update rules for $\\mu_k^{t+1}$ and $\\sigma_k^{t+1}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Double click to edit cell)\n",
    "\n",
    "Please write your update rule for:\n",
    "$\\mu_k^{t+1}$ = \n",
    "\n",
    "\n",
    "Please write your update rule for: $\\sigma_k^{t+1}$ = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999999998341332, 6.546416210160839e-13], [0.9999999999998264, 4.1669481765993814e-16], [0.9999999999890771, 3.72236196954101e-14], [0.9999999920328384, 3.4053943359874215e-11], [0.9999418775452769, 1.4634105550451933e-07], [0.9999999996547153, 1.400411086781523e-12], [0.9999999999999994, 6.6140768435120065e-19], [0.9999999106868837, 3.6800409133513754e-10], [0.9999998172511061, 7.34482856729333e-10], [0.9999993991710125, 2.282163886354633e-09], [0.9999999999629808, 1.3591980151102053e-13], [0.999906976237731, 2.2021982782797092e-07], [0.9999957549850632, 1.4070670560522813e-08], [0.9999964958767533, 1.1800615104881453e-08], [0.999877882810694, 2.784696697706959e-07], [0.9976082124694654, 3.313007554256428e-06], [0.9999383623049914, 1.5403502835986514e-07], [0.999999348859821, 2.4621170022646857e-09], [0.9999904876434856, 2.9311468521204834e-08], [0.9999909362862854, 2.8059365509427906e-08], [0.9999055274244121, 2.231824996828056e-07], [0.9962594895723262, 4.740319545531395e-06], [0.9999999995766057, 1.7285927605674334e-12], [0.9999891161155686, 3.309865414602828e-08], [0.9999999999030321, 3.7387667284375084e-13], [0.9999758650978494, 6.748791024479498e-08], [0.9972769100208823, 3.677118401274507e-06], [0.9999999999621699, 1.3906359089268352e-13], [0.9996106849855112, 7.455131509787316e-07], [0.9999999854383664, 6.208203940806915e-11], [0.9999999994760616, 2.1529161504517948e-12], [0.9999999884525755, 4.9304468338266523e-11], [0.9999972692387108, 9.380032342340231e-09], [0.9999994870157327, 1.9653596676830252e-09], [0.9999992001347501, 2.9884989362771603e-09], [0.9999999999905328, 3.195339788181645e-14], [0.9999998916292965, 4.4382713639564473e-10], [0.9999999998916187, 4.200094156154283e-13], [0.9999996131792774, 1.5036869413248714e-09], [0.8231138142719966, 0.00011527483437251708], [0.9999978125668915, 7.641213998301812e-09], [0.9997614478230326, 4.93278980232869e-07], [0.9998630829901981, 3.0722055580590476e-07], [0.9999983673711557, 5.824604710103274e-09], [0.9999999999999629, 7.557404301289572e-17], [0.9999999981189235, 7.953906714956715e-12], [0.9999999914573936, 3.651071876695641e-11], [0.9997033390588934, 5.931484908155927e-07], [0.9999994619265539, 2.0561983705304647e-09], [0.999381475491643, 1.0969588882151078e-06], [0.9999999951504119, 2.0706512178669557e-11], [0.9999993867785978, 2.326584973955561e-09], [0.9999999999785977, 7.612438354436732e-14], [0.9999999999328362, 2.5444337813849904e-13], [0.9999419056816823, 1.462792006921298e-07], [0.9999990734330303, 3.4311417994041536e-09], [0.9999515459851179, 1.248112467489085e-07], [0.9999999992551029, 3.0904073757056114e-12], [0.9999999002450584, 4.096290843505559e-10], [0.9999998452677297, 6.258636088359515e-10], [0.9999999999794642, 7.285912638593049e-14], [0.9999996698414699, 1.2933109906449211e-09], [0.9999999999938088, 2.0285583429073284e-14], [0.9999955006349872, 1.4840493220753283e-08], [0.9999939525186186, 1.9438141440306404e-08], [0.9999999698523523, 1.2740115959756993e-10], [0.9999985930225807, 5.071198264729228e-09], [0.999999679853894, 1.2559126966653846e-09], [0.9999999999982715, 5.131525144678727e-15], [0.9981316978139385, 2.714192250717342e-06], [0.9999989781093267, 3.76107536935994e-09], [0.9999999993907381, 2.51425196917016e-12], [0.9999999997473282, 1.0136380184912893e-12], [0.9999999999995186, 1.2767654154641307e-15], [0.9999999983907046, 6.787353754307889e-12], [0.9999999999999257, 1.6320099264453664e-16], [0.9999422744847846, 1.4546801991402667e-07], [0.999999187699881, 3.032163157639435e-09], [0.9999999988635372, 4.76139943290113e-12], [0.9999980324926971, 6.926629041973354e-09], [2.904469488530093e-05, 0.99802769107824], [0.0037945661300207243, 0.5689308115306386], [0.0165679625552276, 0.13633290313061192], [5.4166567537921325e-05, 0.996253576164153], [1.254609289185053e-05, 0.9991060153045958], [0.000407000604563024, 0.9622763537520925], [0.06369409911400874, 0.01982013170770967], [0.0028958176845214644, 0.6577357647706885], [0.00010638175883152101, 0.9921553110219894], [1.1096878559502708e-06, 0.9998275267933252], [0.001982455464016279, 0.7635866659540683], [5.2997336111174355e-06, 0.9995600277832837], [2.615161017548318e-05, 0.9982220153347848], [3.733962054151639e-05, 0.9974586012439679], [3.09190235091459e-05, 0.9979006285742029], [8.915971223635294e-06, 0.9993341809129301], [2.629402169635248e-05, 0.9982125014109902], [9.800083616256976e-07, 0.9998359432822989], [0.0002839761961730287, 0.9754760402297178], [0.0036683653862616995, 0.5804804735178118], [2.534055665792553e-06, 0.9997348245375851], [1.8389724843714493e-05, 0.9987323399934278], [1.2549226960857532e-05, 0.9991058171576244], [8.64433900738967e-05, 0.9937776556186984], [0.00016592996617587102, 0.9869622204132246], [0.0001577672987585434, 0.9877017260782631], [0.003359274693278929, 0.6100213268671918], [0.0006893442680596866, 0.9289563570639741], [4.3567320668764706e-05, 0.9970202137828272], [1.0081348404239482e-05, 0.9992611969996852], [0.04650767327862524, 0.03198970490313118], [0.0003493620653201612, 0.9685910532595442], [0.0024973168480122154, 0.7020628901221263], [0.8703628416334461, 8.457804664109919e-05], [1.981213534596688e-06, 0.999770553154047], [1.413493375471131e-05, 0.9990052672371841], [3.907297218772691e-06, 0.9996474614632115], [0.0004958450006440508, 0.9521673227638497], [1.063464014855204e-06, 0.9998305362300485], [1.2018953720622446e-05, 0.9991393114349487], [0.06024971888713114, 0.021591848339287116], [0.5617507337185301, 0.0003992988761980319], [0.2796880188923348, 0.0016937789291283784], [2.352690085449637e-05, 0.9983963940012358], [2.822115243960626e-06, 0.9997163553318437], [4.827177202874528e-05, 0.9966830434578818], [0.0026487926080419207, 0.684858848611402], [0.0008017392856013323, 0.9149386885443103], [1.0406373730761341e-05, 0.9992408020513014], [7.691924601260687e-05, 0.9945287366963536], [0.0008655645905289847, 0.9068559489378235], [7.146484906021179e-07, 0.9998526334848088], [2.4965168027383264e-07, 0.9998677895679678], [0.0023912077143420515, 0.7143668509715362], [0.00041616977032053065, 0.9612529407045337], [1.6921768033319586e-05, 0.998827037015235], [0.016409920522897303, 0.13801509256937786], [2.245036878634267e-05, 0.9984673823260943], [0.0012718690034154339, 0.8543415366430457], [0.00118581047721411, 0.8655374818470911], [0.0009486382928718488, 0.896235301011267], [1.9346214774780946e-06, 0.9997735825757647], [4.931179941809426e-06, 0.9995831040853512], [2.7391286656710003e-06, 0.9997216667070324], [0.0007994623486979527, 0.9152255778482182], [0.0001400225553426871, 0.9892804533671578], [7.77182884638543e-06, 0.9994056668537084], [2.8192363143479944e-05, 0.9980851694025789], [0.06037833232747126, 0.021521221897346964], [0.00012161937606500675, 0.9908733402747053], [3.574695523328771e-05, 0.9975692092542334], [9.781640055023161e-05, 0.9928602284611174], [5.0505981424325385e-05, 0.9965211673208801], [0.01243178762505531, 0.19427017310271213], [1.1297183677762257e-05, 0.9991848028682017], [8.253904919772152e-06, 0.999375562271963], [0.00013776189073792526, 0.9894786311779089], [0.0036244035998733697, 0.5845727722023445], [0.0011456212421270572, 0.8707619630105164], [3.98848175818863e-06, 0.9996423407935446], [0.0034496215305340814, 0.6012001893712994], [0.00012343255653737595, 0.9907185103103643], [5.468142448522689e-05, 0.9962157075723012], [0.0007573474834005836, 0.9205116911664011], [9.179149892503475e-05, 0.9933489463346706], [2.27662261304418e-05, 0.9984465864654585], [6.705764634535143e-07, 0.9998552581898119], [0.00026149263214285, 0.9777655587682443], [0.9600584898804402, 3.078597365404856e-05], [1.3120833305716096e-06, 0.9998142868112653], [9.308440250993453e-06, 0.9993096246188283], [2.9359543028676168e-05, 0.9980064108687905], [2.884154416973266e-06, 0.9997123893510167], [7.584460382776152e-07, 0.9998499664520263], [4.8238953781220474e-05, 0.9966854129594145], [0.00013971598044517863, 0.9893073688710412], [0.00012161239624348296, 0.9908739353752495], [4.0339013748783756e-05, 0.9972486199461557], [0.0003242053038135263, 0.9712776598879407], [8.659798766426313e-06, 0.9993501984510696], [4.96448755496394e-06, 0.999581017100321], [0.004115025008076179, 0.5408942512595447], [0.003438737933406015, 0.6022546094345769], [0.02989844577783671, 0.061106451516971014], [0.00010806580282729003, 0.9920153570097723], [0.7969686507903949, 0.0001337615601473801], [4.486928536376671e-05, 0.9969274086138573], [0.00023732299608037423, 0.9801773052939253], [0.1479631149453647, 0.005135281018315181], [0.00013061773898969778, 0.9901003595354279], [0.0009131388865576565, 0.9007858741972699], [2.119665437428577e-05, 0.9985496611775546], [0.2870922893206383, 0.001614108557893581], [0.12720710139395894, 0.006594161105702755], [0.00023270702733164348, 0.9806317710680192], [7.079359832275715e-05, 0.9950030692615514], [2.4383622333276343e-05, 0.998339678050535], [0.18933191302709826, 0.0033835408809334156], [5.069755942287863e-05, 0.9965072353628252], [0.00017371363511983244, 0.9862495894918898]]\n",
      "[0.42194944483552155, 0.48866559110956936]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "def load(path):\n",
    "    dataset = np.load(path)\n",
    "    return dataset\n",
    "\n",
    "def em(dataset, k, n_iterations):\n",
    "    '''\n",
    "    Input:\n",
    "        dataset - np array - containing the data\n",
    "        k - int - representing the number of underlying gaussian distributions\n",
    "        n_iterations - int - representing number of iterations EM should run for\n",
    "        \n",
    "    output:\n",
    "        mus - np array shape (2,) - mus[k] is the EM estimate of the mean of the kth gaussian\n",
    "        sigmas - np array shape (2,) - sigmas[k] is the EM estimate of the stdev of the kth gaussian\n",
    "        pi - np array shape (2,) - pis[j] is the EM estimate of the prior of the kth gaussian\n",
    "    '''\n",
    "    n_samples = dataset.shape[0]\n",
    "\n",
    "    # Initial guesses for the parameters DO NOT CHANGE\n",
    "    FINAL_INITIAL_MUS = np.asarray([90, 210]) #DO NOT CHANGE\n",
    "    FINAL_INITIAL_SIGMAS = np.asarray([28,19]) #DO NOT CHANGE\n",
    "    FINAL_INITIAL_PIS = np.asarray([0.3,.7]) #DO NOT CHANGE\n",
    "    pis = FINAL_INITIAL_PIS #DO NOT CHANGE\n",
    "    mus = FINAL_INITIAL_MUS #DO NOT CHANGE\n",
    "    sigmas = FINAL_INITIAL_SIGMAS #DO NOT CHANGE\n",
    "            \n",
    "    for em_iter in (range(n_iterations)):\n",
    "            #E Step\n",
    "            '''YOUR E STEP CODE GOES HERE'''\n",
    "            probs = []\n",
    "            for x in dataset:\n",
    "                prob_x_given_k = [(scipy.stats.norm(mus[k], sigmas[k]).pdf(x) * pis[k]) for k in range(k)]\n",
    "                for i in range(len(prob_x_given_k)):\n",
    "                    prob_x_given_k[i] = prob_x_given_k[i]/sum(prob_x_given_k)\n",
    "                probs.append(prob_x_given_k)\n",
    "            print(probs)\n",
    "            \n",
    "            \n",
    "            \n",
    "            '''E STEP CODE END'''\n",
    "            \n",
    "            #M step\n",
    "            '''YOUR M STEP CODE GOES HERE'''\n",
    "            pis = [sum([prob[k] for prob in probs])/len(probs) for k in range(len(pis))]\n",
    "            print(pis)\n",
    "\n",
    "            break\n",
    "            \n",
    "            \n",
    "            \n",
    "            '''M STEP CODE END'''\n",
    "\n",
    "    return pis, mus, sigmas\n",
    "\n",
    "def main():\n",
    "    \n",
    "    n_iterations = 20 #DO NOT CHANGE\n",
    "    k = 2 #DO NOT CHANGE\n",
    "    \n",
    "    '''YOUR TEST CODE HERE'''\n",
    "    #load dataset. assumes data file is in same directory as code file\n",
    "    dataset = np.load(\"EM_dataset.npy\")\n",
    "    pis, mus, sigmas = em(dataset, k, n_iterations)\n",
    "\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
